{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Prerequisite\n",
    "\n",
    "To run this notebook, you need to build the decoder binaries and runtime first. Please refer to [README.md](../LanguageModelDecoder/README.md) for more details.\n",
    "\n",
    "You will need at least **230GB** of free disk space and **100GB** of RAM to run this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare language model training corpus. \n",
    "\n",
    "The training corpus should be a text file with one sentence per line. Here we use [OpenWebText2](https://openwebtext2.readthedocs.io/en/latest/) as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-11-14 07:32:29--  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Resolving mystic.the-eye.eu (mystic.the-eye.eu)... 62.6.154.15\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:34:40--  (try: 2)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:36:52--  (try: 3)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:39:06--  (try: 4)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:41:20--  (try: 5)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:43:37--  (try: 6)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:45:53--  (try: 7)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n",
      "Connecting to mystic.the-eye.eu (mystic.the-eye.eu)|62.6.154.15|:443... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-11-14 07:48:09--  (try: 8)  https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Download the OpenWebText2 corpus\n",
    "\n",
    "CORPUS_DIR=../../data/lm_corpus\n",
    "mkdir -p $CORPUS_DIR\n",
    "# If the download URL does not work, you can find the latest one at https://openwebtext2.readthedocs.io/en/latest/\n",
    "wget https://mystic.the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar -O $CORPUS_DIR/openwebtext2.jsonl.zst.tar\n",
    "cd $CORPUS_DIR\n",
    "tar -xvf openwebtext2.jsonl.zst.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126622ce06d94fac9f8ac8c74a2250af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894476d6dc45463b805350299b8dc970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9aced1ad824eb4bb365c9a335fcaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f3f0ad8af04e0da484101ce24cd834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/132M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f1bf99bc2e452a89020d9262542a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1842236958f744f4a4043320cc089679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e8531145524c69aa45358318c5152a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"suolyer/pile_openwebtext2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'meta'],\n",
      "        num_rows: 33400\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'meta'],\n",
      "        num_rows: 32925\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concatenate all the text files into one big file.\n",
    "Make sure you have python libraries `zstandard`, `jsonlines`, and `tqdm` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zstandard\n",
    "import json\n",
    "import jsonlines\n",
    "import io\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
    "\n",
    "    if isinstance(obj, (datetime.datetime,)):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
    "\n",
    "# Modified version of lm_dataformat Archive for single file.\n",
    "class Archive:\n",
    "    def __init__(self, file_path, compression_level=3):\n",
    "        self.file_path = file_path\n",
    "        dir_name = os.path.dirname(file_path)\n",
    "        if dir_name:\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "        self.fh = open(self.file_path, 'wb')\n",
    "        self.cctx = zstandard.ZstdCompressor(level=compression_level)\n",
    "        self.compressor = self.cctx.stream_writer(self.fh)\n",
    "\n",
    "    def add_data(self, data, meta={}):\n",
    "        self.compressor.write(json.dumps({'text': data, 'meta': meta}, default=json_serial).encode('UTF-8') + b'\\n')\n",
    "\n",
    "    def commit(self):\n",
    "        self.compressor.flush(zstandard.FLUSH_FRAME)\n",
    "        self.fh.flush()\n",
    "        self.fh.close()\n",
    "\n",
    "# Modified version of lm_dataformat Reader with self.fh set, allowing peeking for tqdm.\n",
    "class Reader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_jsonl(self, file, get_meta=False, autojoin_paragraphs=True, para_joiner='\\n\\n'):\n",
    "        with open(file, 'rb') as fh:\n",
    "            self.fh = fh\n",
    "            cctx = zstandard.ZstdDecompressor()\n",
    "            reader = io.BufferedReader(cctx.stream_reader(fh))\n",
    "            rdr = jsonlines.Reader(reader)\n",
    "            for ob in rdr:\n",
    "                # naive jsonl where each object is just the string itself, with no meta. For legacy compatibility.\n",
    "                if isinstance(ob, str):\n",
    "                    assert not get_meta\n",
    "                    yield ob\n",
    "                    continue\n",
    "\n",
    "                text = ob['text']\n",
    "\n",
    "                if autojoin_paragraphs and isinstance(text, list):\n",
    "                    text = para_joiner.join(text)\n",
    "\n",
    "                if get_meta:\n",
    "                    yield text, (ob['meta'] if 'meta' in ob else {})\n",
    "                else:\n",
    "                    yield text\n",
    "\n",
    "lm_corpus_dir = 'lm_corpus'\n",
    "merged_text_path = 'lm_corpus/openwebtext2.txt'\n",
    "output = open(merged_text_path, 'w')\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(lm_corpus_dir, \"*jsonl.zst\")))\n",
    "for file_path in tqdm(files, dynamic_ncols=True):\n",
    "    print(file_path)\n",
    "    reader = Reader()\n",
    "    for document in tqdm(reader.read_jsonl(file_path)):\n",
    "        output.write(document)\n",
    "        output.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download CMU dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://github.com/Alexir/CMUdict/raw/master/cmudict-0.7b -O lm_corpus/cmudict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build language model\n",
    "\n",
    "Build a 3-gram language model based on the OpenWebText2 corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/oak/stanford/groups/shenoy/stfan/code/speechBCI/LanguageModelDecoder/examples/speech/s0\n",
      "/oak/stanford/groups/shenoy/stfan/code/speechBCI/AnalysisExamples/lm_model/data/local/lm\n",
      "Prune LM with threshold 1e-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "set -xe\n",
    "\n",
    "LM_ROOT=../LanguageModelDecoder/examples/speech/s0/\n",
    "LM_CORPUS_DIR=$PWD/lm_corpus\n",
    "LM_MODEL_DIR=$PWD/lm_model\n",
    "\n",
    "cd $LM_ROOT\n",
    "echo $PWD\n",
    ". path.sh\n",
    "\n",
    "# First step is formatting the text corpus.\n",
    "mkdir -p $LM_MODEL_DIR/data/local/lm_data\n",
    "python local/format_lm_data.py \\\n",
    "    --input_text $LM_CORPUS_DIR/openwebtext2.txt \\\n",
    "    --output_text $LM_MODEL_DIR/data/local/lm_data/corpus.txt \\\n",
    "    --dict $LM_CORPUS_DIR/cmudict.txt \\\n",
    "    --unk\n",
    "\n",
    "# Build the LM\n",
    "dict_type=phn\n",
    "lm_order=3\n",
    "prune_threshold=1e-9\n",
    "local/build_lm.sh \\\n",
    "    $LM_MODEL_DIR/data/local/lm_data/corpus.txt \\\n",
    "    $LM_MODEL_DIR/data/local/lm \\\n",
    "    $dict_type \\\n",
    "    $lm_order \\\n",
    "    $prune_threshold \\\n",
    "    $LM_CORPUS_DIR/cmudict.txt\n",
    "\n",
    "# Optionally, if you have 1TB of RAM, you can build a 5-gram LM\n",
    "#dict_type=phn\n",
    "#lm_order=5\n",
    "#prune_threshold=4e-11\n",
    "#local/build_lm.sh \\\n",
    "#    $LM_MODEL_DIR/data/local/lm_data/corpus.txt \\\n",
    "#    $LM_MODEL_DIR/data/local/lm \\\n",
    "#    $dict_type \\\n",
    "#    $lm_order \\\n",
    "#    $prune_threshold \\\n",
    "#    $LM_CORPUS_DIR/cmudict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build WFST decoder graph\n",
    "\n",
    "Convert the previous 3-gram language model into a WFST decoder graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "LM_ROOT=../LanguageModelDecoder/examples/speech/s0/\n",
    "LM_MODEL_DIR=$PWD/lm_model\n",
    "use_all_phones=1\n",
    "dict_type=phn\n",
    "sil_prob=0.9\n",
    "\n",
    "cd $LM_ROOT\n",
    ". path.sh\n",
    "\n",
    "# Prepare L.fst\n",
    "local/prepare_dict_ctc.sh $LM_MODEL_DIR/data/local/lm $LM_MODEL_DIR/data/local/dict_phn $use_all_phones\n",
    "tools/fst/ctc_compile_dict_token.sh --dict-type $dict_type --sil-prob $sil_prob \\\n",
    "    $LM_MODEL_DIR/data/local/dict_phn $LM_MODEL_DIR/data/local/lang_phn_tmp $LM_MODEL_DIR/data/lang_phn\n",
    "\n",
    "# Build TLG decoding graph\n",
    "tools/fst/make_tlg.sh $LM_MODEL_DIR/data/local/lm $LM_MODEL_DIR/data/lang_phn $LM_MODEL_DIR/data/lang_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test loading the deocder graph. Make sure you have [NeuralDecoder](../NeuralDecoder) installed before running this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lm_decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb 셀 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlm_decoder\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mneuralDecoder\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlmDecoderUtils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlmDecoderUtils\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m ngramDecoder \u001b[39m=\u001b[39m lmDecoderUtils\u001b[39m.\u001b[39mbuild_lm_decoder(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlm_model/data/lang_test\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bds2.snu.ac.kr/home/nlp2023/BCI/AnalysisExamples/buildLanguageModel.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lm_decoder'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lm_decoder\n",
    "\n",
    "import neuralDecoder.utils.lmDecoderUtils as lmDecoderUtils\n",
    "\n",
    "ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "    'lm_model/data/lang_test'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
