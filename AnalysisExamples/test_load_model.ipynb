{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights\n",
    "\n",
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print('Attention weights are:')\n",
    "  print(temp_attn)\n",
    "  print('Output is:')\n",
    "  print(temp_out)\n",
    "  \n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "  \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                            self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)\n",
    "  \n",
    "class PartialDecoder(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    x = self.final_layer(x)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights\n",
    "  \n",
    "class AddLayer(Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.math.add(inputs[0], inputs[1])\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    self.addition_layer = AddLayer()\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    # Keras models prefer if you pass all your inputs in the first argument\n",
    "    inp, tar = inputs\n",
    "        \n",
    "    inp_idx = tf.argmax(inp, axis=2)\n",
    "    # print(\"\")\n",
    "    # print(\"INININININININIIN\")\n",
    "    # print(inp.shape)\n",
    "    # print(inp)\n",
    "\n",
    "    enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp_idx, tar)\n",
    "\n",
    "    enc_output = self.encoder(inp_idx, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # print(enc_output.shape)\n",
    "    # print(inp.shape)\n",
    "    # print(\")))))))))))))))))))))))\")\n",
    "    # print(enc_output)\n",
    "    # print(inp)\n",
    "    \n",
    "    mixed_embedding = self.addition_layer([enc_output, inp])\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, inp, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights\n",
    "\n",
    "  def create_masks(self, inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(datasetName):\n",
    "    if datasetName == 'speech':\n",
    "        return SpeechDataset\n",
    "    else:\n",
    "        raise ValueError('Dataset not found')\n",
    "    \n",
    "import pathlib\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "PHONE_DEF = [\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH'\n",
    "]\n",
    "\n",
    "PHONE_DEF_SIL = [\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH', 'SIL'\n",
    "]\n",
    "\n",
    "CHANG_PHONE_DEF = [\n",
    "    'AA', 'AE', 'AH', 'AW',\n",
    "    'AY', 'B',  'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'P', 'R', 'S',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z'\n",
    "]\n",
    "\n",
    "CONSONANT_DEF = ['CH', 'SH', 'JH', 'R', 'B',\n",
    "                 'M',  'W',  'V',  'F', 'P',\n",
    "                 'D',  'N',  'L',  'S', 'T',\n",
    "                 'Z',  'TH', 'G',  'Y', 'HH',\n",
    "                 'K', 'NG', 'ZH', 'DH']\n",
    "VOWEL_DEF = ['EY', 'AE', 'AY', 'EH', 'AA',\n",
    "             'AW', 'IY', 'IH', 'OY', 'OW',\n",
    "             'AO', 'UH', 'AH', 'UW', 'ER']\n",
    "\n",
    "SIL_DEF = ['SIL']\n",
    "\n",
    "class SpeechDataset():\n",
    "    def __init__(self,\n",
    "                 rawFileDir,\n",
    "                 nInputFeatures,\n",
    "                 nClasses,\n",
    "                 maxSeqElements,\n",
    "                 bufferSize,\n",
    "                 syntheticFileDir=None,\n",
    "                 syntheticMixingRate=0.33,\n",
    "                 subsetSize=-1,\n",
    "                 labelDir=None,\n",
    "                 timeWarpSmoothSD=0.0,\n",
    "                 timeWarpNoiseSD=0.0,\n",
    "                 chanIndices=None\n",
    "                 ):\n",
    "\n",
    "        self.rawFileDir = rawFileDir\n",
    "        self.nInputFeatures = nInputFeatures\n",
    "        self.nClasses = nClasses\n",
    "        self.maxSeqElements = maxSeqElements\n",
    "        self.bufferSize = bufferSize\n",
    "        self.syntheticFileDir = syntheticFileDir\n",
    "        self.syntheticMixingRate = syntheticMixingRate\n",
    "        self.timeWarpSmoothSD = timeWarpSmoothSD\n",
    "        self.timeWarpNoiseSD = timeWarpNoiseSD\n",
    "        self.subsetSize = subsetSize\n",
    "        self.chanIndices = chanIndices\n",
    "        \n",
    "    def build(self, batchSize, isTraining):\n",
    "        def _loadDataset(fileDir):\n",
    "            files = sorted([str(x) for x in pathlib.Path(fileDir).glob(\"*.tfrecord\")])\n",
    "            if isTraining:\n",
    "                random.shuffle(files)\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset(files)\n",
    "            return dataset\n",
    "\n",
    "        print(f'Load data from {self.rawFileDir}')\n",
    "        rawDataset = _loadDataset(self.rawFileDir)\n",
    "        if self.syntheticFileDir and self.syntheticMixingRate > 0:\n",
    "            print(f'Load data from {self.syntheticFileDir}')\n",
    "            syntheticDataset = _loadDataset(self.syntheticFileDir)\n",
    "            dataset = tf.data.experimental.sample_from_datasets(\n",
    "                [rawDataset.repeat(), syntheticDataset.repeat()],\n",
    "                weights=[1.0 - self.syntheticMixingRate, self.syntheticMixingRate])\n",
    "        else:\n",
    "            dataset = rawDataset\n",
    "\n",
    "        datasetFeatures = {\n",
    "            \"inputFeatures\": tf.io.FixedLenSequenceFeature([self.nInputFeatures], tf.float32, allow_missing=True),\n",
    "            #\"classLabelsOneHot\": tf.io.FixedLenSequenceFeature([self.nClasses+1], tf.float32, allow_missing=True),\n",
    "            \"newClassSignal\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "            \"ceMask\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "            \"seqClassIDs\": tf.io.FixedLenFeature((self.maxSeqElements), tf.int64),\n",
    "            \"nTimeSteps\": tf.io.FixedLenFeature((), tf.int64),\n",
    "            \"nSeqElements\": tf.io.FixedLenFeature((), tf.int64),\n",
    "            \"transcription\": tf.io.FixedLenFeature((self.maxSeqElements), tf.int64)\n",
    "        }\n",
    "\n",
    "        if self.timeWarpNoiseSD>0 and self.timeWarpSmoothSD>0:\n",
    "            from scipy.ndimage.filters import gaussian_filter1d\n",
    "            inp = np.zeros([200])\n",
    "            inp[int(len(inp)/2)] = 1\n",
    "            gaussKernel = gaussian_filter1d(inp, self.timeWarpSmoothSD)\n",
    "\n",
    "            validIdx = np.argwhere(gaussKernel>0.001)\n",
    "            gaussKernel = gaussKernel[validIdx]\n",
    "            gaussKernel = np.squeeze(gaussKernel/np.sum(gaussKernel))\n",
    "\n",
    "            timeWarpNoiseSD= self.timeWarpNoiseSD\n",
    "\n",
    "            def parseDatasetFunctionWarp(exampleProto):\n",
    "                dat = tf.io.parse_single_example(exampleProto, datasetFeatures)\n",
    "\n",
    "                warpDat = {}\n",
    "                warpDat['seqClassIDs'] = dat['seqClassIDs']\n",
    "                warpDat['nSeqElements'] = dat['nSeqElements']\n",
    "                warpDat['transcription'] = dat['transcription']\n",
    "\n",
    "                whiteNoise = tf.random.normal([dat['nTimeSteps']*2], mean=0, stddev=timeWarpNoiseSD)\n",
    "                rateNoise = tf.nn.conv1d(whiteNoise[tf.newaxis,:,tf.newaxis],\n",
    "                                         gaussKernel[:,np.newaxis,np.newaxis].astype(np.float32), 1, 'SAME')\n",
    "\n",
    "                rateNoise = rateNoise[0,:,0]\n",
    "                toSum = tf.ones([dat['nTimeSteps']*2], dtype=tf.float32) + rateNoise\n",
    "                toSum = tf.nn.relu(toSum)\n",
    "\n",
    "                warpFun = tf.cumsum(toSum)\n",
    "                resampleIdx = tf.cast(warpFun, dtype=tf.int32)\n",
    "                resampleIdx = resampleIdx[resampleIdx<tf.cast(dat['nTimeSteps'],dtype=tf.int32)]\n",
    "\n",
    "                warpDat['nTimeSteps'] = tf.cast(tf.reduce_sum(tf.cast(resampleIdx>-1,dtype=tf.int32)), dtype=tf.int32)\n",
    "                warpDat['inputFeatures'] = tf.gather(dat['inputFeatures'], resampleIdx, axis=0)\n",
    "                if self.chanIndices is not None:\n",
    "                    selectChans = tf.gather(warpDat['inputFeatures'], tf.constant(self.chanIndices),axis=-1)\n",
    "                    paddings = [[0, 0], [0, 256-tf.shape(selectChans)[-1]]]\n",
    "                    warpDat['inputFeatures'] = tf.pad(selectChans, paddings, 'CONSTANT',constant_values=0)\n",
    "                warpDat['newClassSignal'] = tf.gather(dat['newClassSignal'], resampleIdx, axis=0)\n",
    "                warpDat['ceMask'] = tf.gather(dat['ceMask'], resampleIdx, axis=0)\n",
    "\n",
    "                return warpDat\n",
    "\n",
    "            dataset = dataset.map(parseDatasetFunctionWarp, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        else:\n",
    "            def parseDatasetFunctionSimple(exampleProto):\n",
    "                dat = tf.io.parse_single_example(exampleProto, datasetFeatures)\n",
    "                if self.chanIndices is not None:\n",
    "                    newDat = {}\n",
    "                    newDat['seqClassIDs'] = dat['seqClassIDs']\n",
    "                    newDat['nSeqElements'] = dat['nSeqElements']\n",
    "                    newDat['transcription'] = dat['transcription']\n",
    "                    newDat['nTimeSteps'] = dat['nTimeSteps']\n",
    "                    newDat['newClassSignal'] = dat['newClassSignal']\n",
    "                    newDat['ceMask'] = dat['ceMask']\n",
    "                    print(dat['inputFeatures'])\n",
    "                    selectChans = tf.gather(dat['inputFeatures'], tf.constant(self.chanIndices),axis=-1)\n",
    "                    paddings = [[0, 0], [0, 256-tf.shape(selectChans)[-1]]]\n",
    "                    newDat['inputFeatures'] = tf.pad(selectChans, paddings, 'CONSTANT',constant_values=0)\n",
    "                    print(tf.shape(newDat['inputFeatures']))\n",
    "\n",
    "                    return newDat\n",
    "                else:\n",
    "                    return dat\n",
    "            dataset = dataset.map(parseDatasetFunctionSimple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        if isTraining:\n",
    "            # Use all elements to adapt normalization layer\n",
    "            datasetForAdapt = dataset.map(lambda x: x['inputFeatures'] + 0.001,\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            \n",
    "            # Take a subset of the data if specified\n",
    "            if self.subsetSize > 0:\n",
    "                dataset = dataset.take(self.subsetSize)\n",
    "\n",
    "            # Shuffle and transform data if training\n",
    "            dataset = dataset.shuffle(self.bufferSize)\n",
    "            if self.syntheticMixingRate == 0:\n",
    "                dataset = dataset.repeat()\n",
    "            dataset = dataset.padded_batch(batchSize)\n",
    "            dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "            \n",
    "            \n",
    "\n",
    "            return dataset, datasetForAdapt\n",
    "        else:\n",
    "            dataset = dataset.padded_batch(batchSize)\n",
    "            dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "            return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4194201/390306621.py:20: DeprecationWarning: Please use `gaussian_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.special\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import tensorflow_probability as tfp\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf.listconfig import ListConfig\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "record_train_loss = []\n",
    "record_gradNorm = []\n",
    "record_cer = []\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gaussSmooth(inputs, kernelSD=2, padding=\"SAME\"):\n",
    "    \"\"\"\n",
    "    Applies a 1D gaussian smoothing operation with tensorflow to smooth the data along the time axis.\n",
    "\n",
    "    Args:\n",
    "        inputs (tensor : B x T x N): A 3d tensor with batch size B, time steps T, and number of features N\n",
    "        kernelSD (float): standard deviation of the Gaussian smoothing kernel\n",
    "\n",
    "    Returns:\n",
    "        smoothedData (tensor : B x T x N): A smoothed 3d tensor with batch size B, time steps T, and number of features N\n",
    "    \"\"\"\n",
    "\n",
    "    # get gaussian smoothing kernel\n",
    "    inp = np.zeros([100], dtype=np.float32)\n",
    "    inp[50] = 1\n",
    "    gaussKernel = gaussian_filter1d(inp, kernelSD)\n",
    "    validIdx = np.argwhere(gaussKernel > 0.01)\n",
    "    gaussKernel = gaussKernel[validIdx]\n",
    "    gaussKernel = np.squeeze(gaussKernel / np.sum(gaussKernel))\n",
    "\n",
    "    # Apply depth_wise convolution\n",
    "    B, T, C = inputs.shape.as_list()\n",
    "    filters = tf.tile(gaussKernel[None, :, None, None], [1, 1, C, 1])  # [1, W, C, 1]\n",
    "    inputs = inputs[:, None, :, :]  # [B, 1, T, C]\n",
    "    smoothedInputs = tf.nn.depthwise_conv2d(\n",
    "        inputs, filters, strides=[1, 1, 1, 1], padding=padding\n",
    "    )\n",
    "    smoothedInputs = tf.squeeze(smoothedInputs, 1)\n",
    "\n",
    "    return smoothedInputs\n",
    "\n",
    "\n",
    "class NeuralSequenceDecoder(object):\n",
    "    \"\"\"\n",
    "    This class encapsulates all the functionality needed for training, loading and running the neural sequence decoder RNN.\n",
    "    To use it, initialize this class and then call .train() or .inference(). It can also be run from the command line (see bottom\n",
    "    of the script). The args dictionary passed during initialization is used to configure all aspects of its behavior.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        if not os.path.isdir(self.args[\"outputDir\"]):\n",
    "            os.mkdir(self.args[\"outputDir\"])\n",
    "\n",
    "        # record these parameters\n",
    "        if self.args[\"mode\"] == \"train\":\n",
    "            with open(os.path.join(args[\"outputDir\"], \"args.yaml\"), \"w\") as f:\n",
    "                OmegaConf.save(config=self.args, f=f)\n",
    "\n",
    "        # random variable seeding\n",
    "        if self.args[\"seed\"] == -1:\n",
    "            self.args[\"seed\"] = datetime.now().microsecond\n",
    "        np.random.seed(self.args[\"seed\"])\n",
    "        tf.random.set_seed(self.args[\"seed\"])\n",
    "        random.seed(self.args[\"seed\"])\n",
    "        \n",
    "        # Hyperparameters\n",
    "        d_model = 256\n",
    "\n",
    "        self.model = PartialDecoder(\n",
    "                                                num_layers=4, d_model=512, num_heads=4, dff=512,\n",
    "                                                target_vocab_size=45,\n",
    "                                                maximum_position_encoding=5000\n",
    "                                            )\n",
    "\n",
    "        # Compile the model with an appropriate optimizer and loss function\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.learning_rate = CustomSchedule(d_model)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                            epsilon=1e-9)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        self.train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "        \n",
    "        self.count = 0\n",
    "        self.max_wer = 10000\n",
    "\n",
    "        self._prepareForTraining()\n",
    "        \n",
    "    def _save_model(self, path):\n",
    "        # Save the entire model to a file\n",
    "        path = path + \"_model_weights.h5\"\n",
    "        # print(path)\n",
    "        # print(self.args[\"outputDir\"])\n",
    "        # weights_path = os.path.join(self.args[\"outputDir\"], path)\n",
    "        weights_path = self.args[\"outputDir\"] + path\n",
    "        # print(weights_path)\n",
    "        self.model.save_weights(weights_path)\n",
    "        print(f\"Model weights saved to {weights_path}\")\n",
    "        \n",
    "    def _load_model(self, weights_path):\n",
    "        # Load the model weights\n",
    "        dummy_input = tf.constant(tf.random.normal([64, 50, 256]))\n",
    "        \n",
    "        outputLabels = tf.fill((64, 1), 44)\n",
    "        outputLabels = tf.cast(outputLabels, dtype=tf.int64)\n",
    "        \n",
    "        enc_padding_mask, look_ahead_mask, dec_mask = create_masks(tf.argmax(dummy_input, axis=2), outputLabels)\n",
    "\n",
    "        predictions, _ = self.model(outputLabels, dummy_input, False, look_ahead_mask, dec_mask)\n",
    "        self.model.load_weights(weights_path)\n",
    "        print(f\"Model weights loaded from {weights_path}\")\n",
    "\n",
    "    def _buildInputNetworks(self, isTraining):\n",
    "        # Build day transformation and normalization layers (FCNs)\n",
    "        self.nInputLayers = np.max(self.args[\"dataset\"][\"datasetToLayerMap\"]) + 1\n",
    "        self.inputLayers = []\n",
    "        self.normLayers = []\n",
    "        for layerIdx in range(self.nInputLayers):\n",
    "            datasetIdx = np.argwhere(\n",
    "                np.array(self.args[\"dataset\"][\"datasetToLayerMap\"]) == layerIdx\n",
    "            )\n",
    "            datasetIdx = datasetIdx[0, 0]\n",
    "            nInputFeatures = self.args[\"dataset\"][\"nInputFeatures\"]\n",
    "\n",
    "            normLayer = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "                input_shape=[nInputFeatures]\n",
    "            )\n",
    "\n",
    "            if isTraining and self.args[\"normLayer\"]:\n",
    "                normLayer.adapt(self.tfAdaptDatasets[datasetIdx].take(-1))\n",
    "\n",
    "            inputModel = tf.keras.Sequential()\n",
    "            inputModel.add(tf.keras.Input(shape=(None, nInputFeatures)))\n",
    "\n",
    "            for i in range(self.args[\"model\"][\"inputNetwork\"][\"nInputLayers\"]):\n",
    "                if i == 0:\n",
    "                    if (\n",
    "                        self.args[\"model\"][\"inputNetwork\"][\"inputLayerSizes\"][0]\n",
    "                        == nInputFeatures\n",
    "                    ):\n",
    "                        kernelInit = tf.keras.initializers.identity()\n",
    "                    else:\n",
    "                        kernelInit = \"glorot_uniform\"\n",
    "                else:\n",
    "                    if (\n",
    "                        self.args[\"model\"][\"inputNetwork\"][\"inputLayerSizes\"][i]\n",
    "                        == self.args[\"model\"][\"inputNetwork\"][\"inputLayerSizes\"][i - 1]\n",
    "                    ):\n",
    "                        kernelInit = tf.keras.initializers.identity()\n",
    "                    else:\n",
    "                        kernelInit = \"glorot_uniform\"\n",
    "\n",
    "                inputModel.add(\n",
    "                    tf.keras.layers.Dense(\n",
    "                        self.args[\"model\"][\"inputNetwork\"][\"inputLayerSizes\"][i],\n",
    "                        activation=self.args[\"model\"][\"inputNetwork\"][\"activation\"],\n",
    "                        kernel_initializer=kernelInit,\n",
    "                        kernel_regularizer=tf.keras.regularizers.L2(\n",
    "                            self.args[\"model\"][\"weightReg\"]\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "                inputModel.add(\n",
    "                    tf.keras.layers.Dropout(\n",
    "                        rate=self.args[\"model\"][\"inputNetwork\"][\"dropout\"]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            inputModel.trainable = self.args[\"model\"][\"inputNetwork\"].get(\n",
    "                \"trainable\", True\n",
    "            )\n",
    "            inputModel.summary()\n",
    "\n",
    "            self.inputLayers.append(inputModel)\n",
    "            self.normLayers.append(normLayer)\n",
    "\n",
    "    def _buildInputLayers(self, isTraining):\n",
    "        # Build day transformation and normalization layers\n",
    "        self.nInputLayers = np.max(self.args[\"dataset\"][\"datasetToLayerMap\"]) + 1\n",
    "        self.inputLayers = []\n",
    "        self.normLayers = []\n",
    "        for layerIdx in range(self.nInputLayers):\n",
    "            datasetIdx = np.argwhere(\n",
    "                np.array(self.args[\"dataset\"][\"datasetToLayerMap\"]) == layerIdx\n",
    "            )\n",
    "            datasetIdx = datasetIdx[0, 0]\n",
    "\n",
    "            nInputFeatures = self.args[\"dataset\"][\"nInputFeatures\"]\n",
    "\n",
    "            # Adapt normalization layer with all data.\n",
    "            normLayer = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "                input_shape=[nInputFeatures]\n",
    "            )\n",
    "            if isTraining and self.args[\"normLayer\"]:\n",
    "                normLayer.adapt(self.tfAdaptDatasets[datasetIdx].take(-1))\n",
    "\n",
    "            inputLayerSize = self.args[\"model\"].get(\"inputLayerSize\", nInputFeatures)\n",
    "            if inputLayerSize == nInputFeatures:\n",
    "                kernelInit = tf.keras.initializers.identity()\n",
    "            else:\n",
    "                kernelInit = \"glorot_uniform\"\n",
    "            linearLayer = tf.keras.layers.Dense(\n",
    "                inputLayerSize,\n",
    "                kernel_initializer=kernelInit,\n",
    "                kernel_regularizer=tf.keras.regularizers.L2(\n",
    "                    self.args[\"model\"][\"weightReg\"]\n",
    "                ),\n",
    "            )\n",
    "            linearLayer.build(input_shape=[nInputFeatures])\n",
    "\n",
    "            self.inputLayers.append(linearLayer)\n",
    "            self.normLayers.append(normLayer)\n",
    "\n",
    "    def _prepareForTraining(self):\n",
    "        # build the dataset pipelines\n",
    "        self.tfAdaptDatasets = []\n",
    "        self.tfTrainDatasets = []\n",
    "        self.tfValDatasets = []\n",
    "        subsetChans = self.args[\"dataset\"].get(\"subsetChans\", -1)\n",
    "        lastDaySubsetChans = self.args[\"dataset\"].get(\"lastDaySubsetChans\", -1)\n",
    "        TXThreshold = self.args[\"dataset\"].get(\"TXThreshold\", True)\n",
    "        spkPower = self.args[\"dataset\"].get(\"spkPower\", True)\n",
    "        nInputFeatures = self.args[\"dataset\"][\"nInputFeatures\"]\n",
    "        if subsetChans > 0:\n",
    "            if TXThreshold and spkPower:\n",
    "                # nInputFeatures = 2*subsetChans\n",
    "                chanIndices = np.random.permutation(128)[:subsetChans]\n",
    "                chanIndices = np.concatenate((chanIndices, chanIndices + 128))\n",
    "            else:\n",
    "                # nInputFeatures = subsetChans\n",
    "                if TXThreshold:\n",
    "                    chanIndices = np.random.permutation(128)[:subsetChans]\n",
    "                else:\n",
    "                    chanIndices = np.random.permutation(128)[:subsetChans] + 128\n",
    "        else:\n",
    "            chanIndices = None\n",
    "            if \"chanIndices\" in self.args[\"dataset\"]:\n",
    "                chanIndices = np.array(\n",
    "                    list(\n",
    "                        range(\n",
    "                            self.args[\"dataset\"][\"chanIndices\"][0],\n",
    "                            self.args[\"dataset\"][\"chanIndices\"][1],\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            nInputFeatures = self.args[\"dataset\"][\"nInputFeatures\"]\n",
    "\n",
    "        for i, (thisDataset, thisDataDir) in enumerate(\n",
    "            zip(self.args[\"dataset\"][\"sessions\"], self.args[\"dataset\"][\"dataDir\"])\n",
    "        ):\n",
    "            trainDir = os.path.join(thisDataDir, thisDataset, \"train\")\n",
    "            syntheticDataDir = None\n",
    "            if (\n",
    "                self.args[\"dataset\"][\"syntheticMixingRate\"] > 0\n",
    "                and self.args[\"dataset\"][\"syntheticDataDir\"] is not None\n",
    "            ):\n",
    "                if isinstance(self.args[\"dataset\"][\"syntheticDataDir\"], ListConfig):\n",
    "                    if self.args[\"dataset\"][\"syntheticDataDir\"][i] is not None:\n",
    "                        syntheticDataDir = os.path.join(\n",
    "                            self.args[\"dataset\"][\"syntheticDataDir\"][i],\n",
    "                            f\"{thisDataset}_syntheticSentences\",\n",
    "                        )\n",
    "                else:\n",
    "                    syntheticDataDir = os.path.join(\n",
    "                        self.args[\"dataset\"][\"syntheticDataDir\"],\n",
    "                        f\"{thisDataset}_syntheticSentences\",\n",
    "                    )\n",
    "\n",
    "            datasetName = self.args[\"dataset\"][\"name\"]\n",
    "            labelDir = None\n",
    "            labelDirs = self.args[\"dataset\"].get(\"labelDir\", None)\n",
    "            if labelDirs is not None and labelDirs[i] is not None:\n",
    "                labelDir = os.path.join(labelDirs[i], thisDataset)\n",
    "\n",
    "            lastDaySubsetSize = self.args[\"dataset\"].get(\"lastDaySubsetSize\", -1)\n",
    "            if (\n",
    "                i == (len(self.args[\"dataset\"][\"sessions\"]) - 1)\n",
    "                and lastDaySubsetSize != -1\n",
    "            ):\n",
    "                subsetSize = lastDaySubsetSize\n",
    "            else:\n",
    "                subsetSize = self.args[\"dataset\"].get(\"subsetSize\", -1)\n",
    "\n",
    "            newTrainDataset = getDataset(datasetName)(\n",
    "                trainDir,\n",
    "                nInputFeatures,\n",
    "                self.args[\"dataset\"][\"nClasses\"],\n",
    "                self.args[\"dataset\"][\"maxSeqElements\"],\n",
    "                self.args[\"dataset\"][\"bufferSize\"],\n",
    "                syntheticDataDir,\n",
    "                0\n",
    "                if syntheticDataDir is None\n",
    "                else self.args[\"dataset\"][\"syntheticMixingRate\"],\n",
    "                subsetSize,\n",
    "                labelDir,\n",
    "                self.args[\"dataset\"].get(\"timeWarpSmoothSD\", 0),\n",
    "                self.args[\"dataset\"].get(\"timeWarpNoiseSD\", 0),\n",
    "                chanIndices=chanIndices,\n",
    "            )\n",
    "\n",
    "            newTrainDataset, newDatasetForAdapt = newTrainDataset.build(\n",
    "                self.args[\"batchSize\"], isTraining=True\n",
    "            )\n",
    "\n",
    "            testOnTrain = self.args[\"dataset\"].get(\"testOnTrain\", False)\n",
    "            if \"testDir\" in self.args.keys():\n",
    "                testDir = self.args[\"testDir\"]\n",
    "            else:\n",
    "                testDir = \"test\"\n",
    "            valDir = os.path.join(\n",
    "                thisDataDir, thisDataset, testDir if not testOnTrain else \"train\"\n",
    "            )\n",
    "\n",
    "            newValDataset = getDataset(datasetName)(\n",
    "                valDir,\n",
    "                nInputFeatures,\n",
    "                self.args[\"dataset\"][\"nClasses\"],\n",
    "                self.args[\"dataset\"][\"maxSeqElements\"],\n",
    "                self.args[\"dataset\"][\"bufferSize\"],\n",
    "                chanIndices=chanIndices,\n",
    "            )\n",
    "            newValDataset = newValDataset.build(\n",
    "                self.args[\"batchSize\"], isTraining=False\n",
    "            )\n",
    "\n",
    "            self.tfAdaptDatasets.append(newDatasetForAdapt)\n",
    "            self.tfTrainDatasets.append(newTrainDataset)\n",
    "            self.tfValDatasets.append(newValDataset)\n",
    "\n",
    "        # Define input layers, including feature normalization which is adapted on the training data\n",
    "        if \"inputNetwork\" in self.args[\"model\"]:\n",
    "            self._buildInputNetworks(isTraining=True)\n",
    "        else:\n",
    "            self._buildInputLayers(isTraining=True)\n",
    "\n",
    "        # Train dataset selector. Used for switch between different day's data during training.\n",
    "        self.trainDatasetSelector = {}\n",
    "        self.trainDatasetIterators = [iter(d) for d in self.tfTrainDatasets]\n",
    "        for x in range(len(self.args[\"dataset\"][\"sessions\"])):\n",
    "            self.trainDatasetSelector[x] = lambda x=x: self._datasetLayerTransform(\n",
    "                self.trainDatasetIterators[x].get_next(),\n",
    "                self.normLayers[self.args[\"dataset\"][\"datasetToLayerMap\"][x]],\n",
    "                self.args[\"dataset\"][\"whiteNoiseSD\"],\n",
    "                self.args[\"dataset\"][\"constantOffsetSD\"],\n",
    "                self.args[\"dataset\"][\"randomWalkSD\"],\n",
    "                self.args[\"dataset\"][\"staticGainSD\"],\n",
    "                self.args[\"dataset\"].get(\"randomCut\", 0),\n",
    "            )\n",
    "\n",
    "        # clear old checkpoints\n",
    "        ckptFiles = [str(x) for x in Path(self.args[\"outputDir\"]).glob(\"ckpt-*\")]\n",
    "        for file in ckptFiles:\n",
    "            os.remove(file)\n",
    "\n",
    "        if os.path.isfile(self.args[\"outputDir\"] + \"/checkpoint\"):\n",
    "            os.remove(self.args[\"outputDir\"] + \"/checkpoint\")\n",
    "\n",
    "        # saving/loading\n",
    "        ckptVars = {}\n",
    "        ckptVars[\"net\"] = self.model\n",
    "        for x in range(len(self.normLayers)):\n",
    "            ckptVars[\"normLayer_\" + str(x)] = self.normLayers[x]\n",
    "            ckptVars[\"inputLayer_\" + str(x)] = self.inputLayers[x]\n",
    "\n",
    "        # Resume if checkpoint exists in outputDir\n",
    "        resume = os.path.exists(os.path.join(self.args[\"outputDir\"], \"checkpoint\"))\n",
    "        if resume:\n",
    "            # Resume training, so we need to load optimizer and step from checkpoint.\n",
    "            ckptVars[\"step\"] = tf.Variable(0)\n",
    "            ckptVars[\"bestValCer\"] = tf.Variable(1.0)\n",
    "            ckptVars[\"optimizer\"] = self.optimizer\n",
    "            self.checkpoint = tf.train.Checkpoint(**ckptVars)\n",
    "            ckptPath = tf.train.latest_checkpoint(self.args[\"outputDir\"])\n",
    "            # If in infer mode, we may want to load a particular checkpoint idx\n",
    "            if self.args[\"mode\"] == \"infer\":\n",
    "                if self.args[\"loadCheckpointIdx\"] is not None:\n",
    "                    ckptPath = os.path.join(\n",
    "                        self.args[\"outputDir\"], f'ckpt-{self.args[\"loadCheckpointIdx\"]}'\n",
    "                    )\n",
    "            print(\"Loading from : \" + ckptPath)\n",
    "            self.checkpoint.restore(ckptPath).expect_partial()\n",
    "        else:\n",
    "            if self.args[\"loadDir\"] != None and os.path.exists(\n",
    "                os.path.join(self.args[\"loadDir\"], \"checkpoint\")\n",
    "            ):\n",
    "                if self.args[\"loadCheckpointIdx\"] is not None:\n",
    "                    ckptPath = os.path.join(\n",
    "                        self.args[\"loadDir\"], f'ckpt-{self.args[\"loadCheckpointIdx\"]}'\n",
    "                    )\n",
    "                else:\n",
    "                    ckptPath = tf.train.latest_checkpoint(self.args[\"loadDir\"])\n",
    "\n",
    "                print(\"Loading from : \" + ckptPath)\n",
    "                self.checkpoint = tf.train.Checkpoint(**ckptVars)\n",
    "                self.checkpoint.restore(ckptPath)\n",
    "\n",
    "                if (\n",
    "                    \"copyInputLayer\" in self.args[\"dataset\"]\n",
    "                    and self.args[\"dataset\"][\"copyInputLayer\"] is not None\n",
    "                ):\n",
    "                    print(self.args[\"dataset\"][\"copyInputLayer\"].items())\n",
    "                    for t, f in self.args[\"dataset\"][\"copyInputLayer\"].items():\n",
    "                        for vf, vt in zip(\n",
    "                            self.inputLayers[int(f)].variables,\n",
    "                            self.inputLayers[int(t)].variables,\n",
    "                        ):\n",
    "                            vt.assign(vf)\n",
    "\n",
    "                # After loading, we need to put optimizer and step back to checkpoint in order to save them.\n",
    "                ckptVars[\"step\"] = tf.Variable(0)\n",
    "                ckptVars[\"bestValCer\"] = tf.Variable(1.0)\n",
    "                ckptVars[\"optimizer\"] = self.optimizer\n",
    "                self.checkpoint = tf.train.Checkpoint(**ckptVars)\n",
    "            else:\n",
    "                # Nothing to load.\n",
    "                ckptVars[\"step\"] = tf.Variable(0)\n",
    "                ckptVars[\"bestValCer\"] = tf.Variable(1.0)\n",
    "                ckptVars[\"optimizer\"] = self.optimizer\n",
    "                self.checkpoint = tf.train.Checkpoint(**ckptVars)\n",
    "\n",
    "        self.ckptManager = tf.train.CheckpointManager(\n",
    "            self.checkpoint,\n",
    "            self.args[\"outputDir\"],\n",
    "            max_to_keep=None if self.args[\"batchesPerSave\"] > 0 else 10,\n",
    "        )\n",
    "\n",
    "        # Tensorboard summary\n",
    "        if self.args[\"mode\"] == \"train\":\n",
    "            self.summary_writer = tf.summary.create_file_writer(self.args[\"outputDir\"])\n",
    "\n",
    "    # train에서 그 data 들 dictionary 원본\n",
    "    def _datasetLayerTransform(\n",
    "        self,\n",
    "        dat,\n",
    "        normLayer,\n",
    "        whiteNoiseSD,\n",
    "        constantOffsetSD,\n",
    "        randomWalkSD,\n",
    "        staticGainSD,\n",
    "        randomCut,\n",
    "    ):\n",
    "        features = dat[\"inputFeatures\"]\n",
    "        features = normLayer(dat[\"inputFeatures\"])\n",
    "\n",
    "        featShape = tf.shape(features)\n",
    "        batchSize = featShape[0]\n",
    "        featDim = featShape[2]\n",
    "        if staticGainSD > 0:\n",
    "            warpMat = tf.tile(\n",
    "                tf.eye(features.shape[2])[tf.newaxis, :, :], [batchSize, 1, 1]\n",
    "            )\n",
    "            warpMat += tf.random.normal(tf.shape(warpMat), mean=0, stddev=staticGainSD)\n",
    "            features = tf.linalg.matmul(features, warpMat)\n",
    "\n",
    "        if whiteNoiseSD > 0:\n",
    "            features += tf.random.normal(featShape, mean=0, stddev=whiteNoiseSD)\n",
    "\n",
    "        if constantOffsetSD > 0:\n",
    "            features += tf.random.normal(\n",
    "                [batchSize, 1, featDim], mean=0, stddev=constantOffsetSD\n",
    "            )\n",
    "\n",
    "        if randomWalkSD > 0:\n",
    "            features += tf.math.cumsum(\n",
    "                tf.random.normal(featShape, mean=0, stddev=randomWalkSD),\n",
    "                axis=self.args[\"randomWalkAxis\"],\n",
    "            )\n",
    "\n",
    "        if randomCut > 0:\n",
    "            cut = np.random.randint(0, randomCut)\n",
    "            features = features[:, cut:, :]\n",
    "            dat[\"nTimeSteps\"] = dat[\"nTimeSteps\"] - cut\n",
    "\n",
    "        if self.args[\"smoothInputs\"]:\n",
    "            features = gaussSmooth(features, kernelSD=self.args[\"smoothKernelSD\"])\n",
    "\n",
    "        if self.args[\"lossType\"] == \"ctc\":\n",
    "            outDict = {\n",
    "                \"inputFeatures\": features,\n",
    "                #'classLabelsOneHot': dat['classLabelsOneHot'],\n",
    "                \"newClassSignal\": dat[\"newClassSignal\"],\n",
    "                \"seqClassIDs\": dat[\"seqClassIDs\"],\n",
    "                \"nTimeSteps\": dat[\"nTimeSteps\"],\n",
    "                \"nSeqElements\": dat[\"nSeqElements\"],\n",
    "                \"ceMask\": dat[\"ceMask\"],\n",
    "                \"transcription\": dat[\"transcription\"],\n",
    "            }\n",
    "        elif self.args[\"lossType\"] == \"ce\":\n",
    "            outDict = {\n",
    "                \"inputFeatures\": features,\n",
    "                \"classLabelsOneHot\": dat[\"classLabelsOneHot\"],\n",
    "                \"newClassSignal\": dat[\"newClassSignal\"],\n",
    "                \"seqClassIDs\": dat[\"seqClassIDs\"],\n",
    "                \"nTimeSteps\": dat[\"nTimeSteps\"],\n",
    "                \"nSeqElements\": dat[\"nSeqElements\"],\n",
    "                \"ceMask\": dat[\"ceMask\"],\n",
    "                \"transcription\": dat[\"transcription\"],\n",
    "            }\n",
    "\n",
    "        return outDict\n",
    "\n",
    "    def train(self):\n",
    "        perBatchData_train = np.zeros([self.args[\"nBatchesToTrain\"] + 1, 6])\n",
    "        perBatchData_val = np.zeros([self.args[\"nBatchesToTrain\"] + 1, 6])\n",
    "\n",
    "        # Restore snapshot\n",
    "        restoredStep = int(self.checkpoint.step)\n",
    "        if restoredStep > 0:\n",
    "            outputSnapshot = scipy.io.loadmat(\n",
    "                self.args[\"outputDir\"] + \"/outputSnapshot\"\n",
    "            )\n",
    "            perBatchData_train = outputSnapshot[\"perBatchData_train\"]\n",
    "            perBatchData_val = outputSnapshot[\"perBatchData_val\"]\n",
    "\n",
    "        saveBestCheckpoint = self.args[\"batchesPerSave\"] == 0\n",
    "        bestValCer = self.checkpoint.bestValCer\n",
    "        print(\"bestVal-WER: \" + str(bestValCer))\n",
    "        for batchIdx in range(restoredStep, self.args[\"nBatchesToTrain\"] + 1):\n",
    "            # --training--\n",
    "            if self.args[\"dataset\"][\"datasetProbability\"] is None:\n",
    "                nSessions = len(self.args[\"dataset\"][\"sessions\"])\n",
    "                self.args[\"dataset\"][\"datasetProbability\"] = [\n",
    "                    1.0 / nSessions\n",
    "                ] * nSessions\n",
    "            datasetIdx = int(\n",
    "                np.argwhere(\n",
    "                    np.random.multinomial(1, self.args[\"dataset\"][\"datasetProbability\"])\n",
    "                )[0][0]\n",
    "            )\n",
    "            \n",
    "            layerIdx = self.args[\"dataset\"][\"datasetToLayerMap\"][datasetIdx]\n",
    "            \n",
    "            dtStart = datetime.now()\n",
    "            try:\n",
    "                sample_input, sample_output, seqLength = self._trainStep(\n",
    "                    tf.constant(datasetIdx, dtype=tf.int32),\n",
    "                    tf.constant(layerIdx, dtype=tf.int32),\n",
    "                )\n",
    "\n",
    "                self.checkpoint.step.assign_add(1)\n",
    "                totalSeconds = (datetime.now() - dtStart).total_seconds()\n",
    "                # self._addRowToStatsTable(\n",
    "                #     perBatchData_train, batchIdx, totalSeconds, trainOut, True\n",
    "                # )\n",
    "                print(\n",
    "                    f\"Train batch {batchIdx}: \"\n",
    "                    + f'loss: {self.train_loss.result():.8f} '\n",
    "                    + f'Accuracy: {self.train_accuracy.result():.8f} '\n",
    "                    + f\"time {totalSeconds:.2f}\"\n",
    "                )\n",
    "                \n",
    "                record_train_loss.append(self.train_loss.result())       \n",
    "                \n",
    "            except tf.errors.InvalidArgumentError as e:\n",
    "                print(e)\n",
    "            \n",
    "            # --validation--\n",
    "            if batchIdx % self.args[\"batchesPerVal\"] == 0 and batchIdx != 0:\n",
    "                \n",
    "                # print(\"------------------- Train Sample Result ----------------\")\n",
    "                # print(sample_input[0][:seqLength[0] + 2].numpy())\n",
    "                # print(sample_output[0][:seqLength[0] + 2].numpy())\n",
    "                \n",
    "                dtStart = datetime.now()\n",
    "                valOutputs = self.inference()\n",
    "                \n",
    "                avg_wer = np.average(valOutputs[\"wer\"])\n",
    "\n",
    "                totalSeconds = (datetime.now() - dtStart).total_seconds()\n",
    "                                \n",
    "                print(\n",
    "                    f\"Val batch {batchIdx}: \"\n",
    "                    + f'WER: {avg_wer} '\n",
    "                    + f\"time {totalSeconds:.2f}\"\n",
    "                )\n",
    "                # print(valOutputs[\"targetSentences\"])\n",
    "                # print(valOutputs[\"decodedSentences\"])\n",
    "                # print(\"-------------------- EXAMPLE -------------------\")\n",
    "                # # Target : Phoneme\n",
    "                # print(\"Target : \" + str(valOutputs[\"targetSentences\"][0][0][:valOutputs[\"targetLength\"][0][0]]))\n",
    "                # print(\"Output : \" + str(valOutputs[\"decodedSentences\"][0][0][:valOutputs[\"targetLength\"][0][0]]))\n",
    "                # print(f\"WER {self.max_wer} -> {avg_wer}\")\n",
    "                \n",
    "                if saveBestCheckpoint and avg_wer < bestValCer:\n",
    "                    bestValCer = avg_wer\n",
    "                    self.checkpoint.bestValCer.assign(bestValCer)\n",
    "                    savedCkpt = self.ckptManager.save(checkpoint_number=batchIdx)\n",
    "                    print(f\"Checkpoint saved {savedCkpt}\")\n",
    "                \n",
    "                record_cer.append(avg_wer)\n",
    "                \n",
    "                if self.max_wer < avg_wer and avg_wer < 0.0001:\n",
    "                    file_name = \"/Early_Stop_\" + str(batchIdx)\n",
    "                    break\n",
    "                else:\n",
    "                    file_name = \"/\" + str(batchIdx)\n",
    "                    self.max_wer = avg_wer\n",
    "                    \n",
    "                self._save_model(file_name)\n",
    "\n",
    "            if (\n",
    "                self.args[\"batchesPerSave\"] > 0\n",
    "                and batchIdx % self.args[\"batchesPerSave\"] == 0\n",
    "            ):\n",
    "                savedCkpt = self.ckptManager.save(checkpoint_number=batchIdx)\n",
    "                print(f\"Checkpoint saved {savedCkpt}\")\n",
    "                \n",
    "        with open('../record_train_loss.pkl', 'wb') as file:\n",
    "            pickle.dump(record_train_loss, file)\n",
    "        with open('../record_wer.pkl', 'wb') as file:\n",
    "            pickle.dump(record_cer, file)\n",
    "            \n",
    "        return float(bestValCer)\n",
    "\n",
    "    def inference(self, returnData=False, load=False, weights_path=None):\n",
    "        # run through the specified dataset a single time and return the outputs\n",
    "        if(load):\n",
    "            self.model.load_weights(weights_path)\n",
    "        infOut = {}\n",
    "        infOut[\"logits\"] = []\n",
    "        infOut[\"inferSeqs\"] = []\n",
    "        infOut[\"transcription\"] = []\n",
    "        infOut[\"targetSentences\"] = []\n",
    "        infOut[\"targetLength\"] = []\n",
    "        infOut[\"decodedSentences\"] = []\n",
    "        infOut[\"wer\"] = []\n",
    "        allData = []\n",
    "\n",
    "        print(\"--------------- Start Validation Step --------------\")\n",
    "\n",
    "        for datasetIdx, valProb in enumerate(\n",
    "            self.args[\"dataset\"][\"datasetProbabilityVal\"]\n",
    "        ):\n",
    "            # print(str(datasetIdx) + \"/\" + str(len(self.args[\"dataset\"][\"datasetProbabilityVal\"])))\n",
    "            \n",
    "            if valProb <= 0:\n",
    "                continue\n",
    "\n",
    "            layerIdx = self.args[\"dataset\"][\"datasetToLayerMap\"][datasetIdx]\n",
    "            \n",
    "            \n",
    "            for data in self.tfValDatasets[datasetIdx]:\n",
    "                \n",
    "                out = self._valStep(data, layerIdx)\n",
    "\n",
    "                infOut[\"logits\"].append(out[\"logits\"].numpy())\n",
    "                infOut[\"transcription\"].append(out[\"transcription\"].numpy())\n",
    "                infOut[\"inferSeqs\"].append(out[\"inferSeqs\"].numpy())\n",
    "                infOut[\"targetSentences\"].append(out[\"targetSentences\"])\n",
    "                infOut[\"targetLength\"].append(out[\"targetLength\"])\n",
    "                infOut[\"decodedSentences\"].append(out[\"decodedSentences\"])\n",
    "                infOut[\"wer\"].append(out[\"wer\"])\n",
    "\n",
    "        if returnData:\n",
    "            return infOut, allData\n",
    "        else:\n",
    "            return infOut\n",
    "\n",
    "    def _addRowToStatsTable(\n",
    "        self, currentTable, batchIdx, computationTime, minibatchOutput, isTrainBatch\n",
    "    ):\n",
    "        currentTable[batchIdx, :] = np.array(\n",
    "            [\n",
    "                batchIdx,\n",
    "                computationTime,\n",
    "                minibatchOutput[\"predictionLoss\"] if isTrainBatch else 0.0,\n",
    "                minibatchOutput[\"regularizationLoss\"] if isTrainBatch else 0.0,\n",
    "                tf.reduce_mean(minibatchOutput[\"seqErrorRate\"]),\n",
    "                minibatchOutput[\"gradNorm\"] if isTrainBatch else 0.0,\n",
    "            ],\n",
    "            dtype=object,\n",
    "        )\n",
    "\n",
    "        prefix = \"train\" if isTrainBatch else \"val\"\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            if isTrainBatch:\n",
    "                tf.summary.scalar(\n",
    "                    f\"{prefix}/predictionLoss\",\n",
    "                    minibatchOutput[\"predictionLoss\"],\n",
    "                    step=batchIdx,\n",
    "                )\n",
    "                tf.summary.scalar(\n",
    "                    f\"{prefix}/regLoss\",\n",
    "                    minibatchOutput[\"regularizationLoss\"],\n",
    "                    step=batchIdx,\n",
    "                )\n",
    "                tf.summary.scalar(\n",
    "                    f\"{prefix}/gradNorm\", minibatchOutput[\"gradNorm\"], step=batchIdx\n",
    "                )\n",
    "            tf.summary.scalar(\n",
    "                f\"{prefix}/seqErrorRate\",\n",
    "                tf.reduce_mean(minibatchOutput[\"seqErrorRate\"]),\n",
    "                step=batchIdx,\n",
    "            )\n",
    "            tf.summary.scalar(\n",
    "                f\"{prefix}/computationTime\", computationTime, step=batchIdx\n",
    "            )\n",
    "            # if isTrainBatch:\n",
    "            #    tf.summary.scalar(\n",
    "            #        f'{prefix}/lr', self.optimizer._decayed_lr(tf.float32), step=batchIdx)\n",
    "\n",
    "    @tf.function()\n",
    "    def _trainStep(self, datasetIdx, layerIdx):\n",
    "        \n",
    "        data = tf.switch_case(datasetIdx, self.trainDatasetSelector)\n",
    "        \n",
    "        inputTransformSelector = {}\n",
    "        for x in range(self.nInputLayers):\n",
    "            inputTransformSelector[x] = lambda x=x: self.inputLayers[x](\n",
    "                data[\"inputFeatures\"], training=True\n",
    "            )\n",
    "\n",
    "        regLossSelector = {}\n",
    "        for x in range(self.nInputLayers):\n",
    "            regLossSelector[x] = lambda x=x: self.inputLayers[x].losses\n",
    "                    \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            inputTransformedFeatures = tf.switch_case(layerIdx, inputTransformSelector)\n",
    "            \n",
    "            # Target : Charactor\n",
    "            # padded_tensor = tf.pad(data[\"transcription\"], paddings=[[0, 0], [1, 0]], constant_values=149)\n",
    "            \n",
    "            # Target : Phoneme\n",
    "            padded_tensor = tf.pad(data[\"seqClassIDs\"], paddings=[[0, 0], [1, 0]], constant_values=44)\n",
    "            \n",
    "            # Transformer\n",
    "            # predictions, _ = self.model([inputTransformedFeatures, padded_tensor[:,:-1]], training = True)\n",
    "            \n",
    "            # Only Decoder\n",
    "            enc_padding_mask, look_ahead_mask, dec_mask = create_masks(tf.argmax(inputTransformedFeatures, axis=2),padded_tensor[:,:-1])\n",
    "            \n",
    "            \n",
    "            predictions, _ = self.model(padded_tensor[:,:-1], inputTransformedFeatures, True, look_ahead_mask, dec_mask)\n",
    "                \n",
    "            #Target : Charactor\n",
    "            # loss = loss_function(data[\"transcription\"], predictions)\n",
    "            \n",
    "            #Target : Phoneme\n",
    "            loss = loss_function(data[\"seqClassIDs\"], predictions)\n",
    "    \n",
    "        gradients = tape.gradient(loss,self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "        self.train_loss(loss)\n",
    "        # self.train_accuracy(accuracy_function(data[\"transcription\"], predictions))\n",
    "        self.train_accuracy(accuracy_function(data[\"seqClassIDs\"], predictions))\n",
    "        \n",
    "        return padded_tensor, tf.argmax(predictions, axis=-1), data[\"nSeqElements\"]\n",
    "\n",
    "    def _valStep(self, data, layerIdx):\n",
    "        data = self._datasetLayerTransform(\n",
    "            data, self.normLayers[layerIdx], 0, 0, 0, 0, 0\n",
    "        )\n",
    "\n",
    "        # channel zeroing\n",
    "        if \"channelMask\" in self.args.keys():\n",
    "            maskedFeatures = data[\"inputFeatures\"] * tf.constant(\n",
    "                np.array(self.args[\"channelMask\"])[np.newaxis, np.newaxis, :],\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "            print(\"masking\")\n",
    "        else:\n",
    "            maskedFeatures = data[\"inputFeatures\"]\n",
    "\n",
    "        inputTransformedFeatures = self.inputLayers[layerIdx](\n",
    "            maskedFeatures, training=False\n",
    "        )\n",
    "        \n",
    "        target_sent = []\n",
    "        target_length = []\n",
    "        # Target : Charactor\n",
    "        # for seq in data[\"transcription\"]:\n",
    "        #     endIdx = tf.argmax(tf.cast(tf.equal(seq, 0), tf.int32)).numpy()\n",
    "        #     target_length.append(endIdx)\n",
    "        #     characters = [chr(value) for value in seq]\n",
    "        #     result_string = ''.join(characters)\n",
    "        #     removed = result_string[:endIdx]\n",
    "        #     target_sent.append(removed)\n",
    "        \n",
    "        print(\"-------------------- FIND PROPER END STEP ------------------------\")\n",
    "        print()\n",
    "        print(\"SAMPLES\")\n",
    "        print(data['nSeqElements'])\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        # print(data['classLabelsOneHot'])\n",
    "        print()\n",
    "        \n",
    "        # Target : Phoneme\n",
    "        for seq in data[\"seqClassIDs\"]:\n",
    "            endIdx = tf.argmax(tf.cast(tf.equal(seq, 0), tf.int32)).numpy()\n",
    "            target_length.append(endIdx)\n",
    "            phoneme_idx = [value.numpy() for value in seq]\n",
    "            target_sent.append(phoneme_idx)\n",
    "            \n",
    "        outputLabels = tf.fill((inputTransformedFeatures.shape[0], 1), 44)\n",
    "        outputLabels = tf.cast(outputLabels, dtype=tf.int64)\n",
    "        \n",
    "        # output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        # output_array = output_array.write(0, 149)\n",
    "    \n",
    "        # In Real Inference\n",
    "        for i in range(100):\n",
    "\n",
    "            enc_padding_mask, look_ahead_mask, dec_mask = create_masks(tf.argmax(inputTransformedFeatures, axis=2),outputLabels)\n",
    "            \n",
    "            # Only Decoder\n",
    "            predictions, _ = self.model(outputLabels, inputTransformedFeatures, True, look_ahead_mask, dec_mask)\n",
    "            \n",
    "            # output = tf.transpose(output_array.stack())\n",
    "            # predictions, _ = self.model([inputTransformedFeatures, output], training = False)\n",
    "            # print(\"Predict\")\n",
    "            # print(outputLabels)\n",
    "            # print(predictions)\n",
    "            # print(predictions.shape)\n",
    "            # 20 1 150\n",
    "            full_pred = predictions\n",
    "            predictions = predictions[:,-1:,:]\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "            # nextLabels = tf.argmax(predictions, axis=2)\n",
    "            \n",
    "            # print(\"Output Lables\")\n",
    "            # print(predicted_id)\n",
    "\n",
    "            # print(\"Concated Next Labels\")\n",
    "            # output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "            outputLabels = tf.concat([outputLabels, predicted_id], axis=1)\n",
    "            # print(outputLabels)\n",
    "            \n",
    "        # Target : Charactor\n",
    "        # output_sent = []\n",
    "        # for idx in range(len(outputLabels)):\n",
    "        #     characters = [chr(value) for value in outputLabels[idx]]\n",
    "        #     result_string = ''.join(characters)\n",
    "        #     removed = result_string[1:target_length[idx]+1]\n",
    "        #     output_sent.append(removed)\n",
    "            \n",
    "        # Target : Phoneme\n",
    "        # print(outputLabels) # 20, 71\n",
    "        # print(full_pred)  # 20, 70, 45\n",
    "        # print(tf.argmax(full_pred, axis=2)) # 20 70\n",
    "        # print(data[\"seqClassIDs\"]) # 20, 500\n",
    "        # print(data[\"seqClassIDs\"][:,:outputLabels.shape[1]]) # 20, 71\n",
    "        \n",
    "        output_sent = []\n",
    "        for idx in range(len(outputLabels)):\n",
    "            output_idx = [value.numpy() for value in outputLabels[idx]]\n",
    "            output_sent.append(output_idx[1:])\n",
    "        # Target : Phoneme\n",
    "        print(\"Target : \" + str(target_sent[0][:100]))\n",
    "        print(\"Output : \" + str(output_sent[0][:100]))\n",
    "        \n",
    "        s_wer = 0\n",
    "        for idx in range(len(target_sent)):\n",
    "            # s_wer += wer(target_sent[idx], output_sent[idx])\n",
    "            s_wer += calculate_cer(target_sent[idx], output_sent[idx])\n",
    "            # print(s_wer)\n",
    "        s_wer /= len(target_sent)\n",
    "\n",
    "        output = {}\n",
    "        output[\"logits\"] = predictions\n",
    "        output[\"inferSeqs\"] = outputLabels\n",
    "        \n",
    "        output[\"transcription\"] = data[\"transcription\"]\n",
    "        output[\"targetSentences\"] = target_sent\n",
    "        output[\"targetSentences\"] = target_sent\n",
    "        output[\"targetLength\"] = target_length\n",
    "        \n",
    "        output[\"decodedSentences\"] = output_sent\n",
    "        \n",
    "        output[\"wer\"] = s_wer\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def timeWarpDataElement(dat, timeScalingRange):\n",
    "    warpDat = {}\n",
    "    warpDat[\"seqClassIDs\"] = dat[\"seqClassIDs\"]\n",
    "    warpDat[\"nSeqElements\"] = dat[\"nSeqElements\"]\n",
    "    warpDat[\"transcription\"] = dat[\"transcription\"]\n",
    "\n",
    "    # nTimeSteps, inputFeatures need to be modified\n",
    "    globalTimeFactor = (\n",
    "        1 + (tf.random.uniform(shape=[], dtype=tf.float32) - 0.5) * timeScalingRange\n",
    "    )\n",
    "    warpDat[\"nTimeSteps\"] = tf.cast(\n",
    "        tf.cast(dat[\"nTimeSteps\"], dtype=tf.float32) * globalTimeFactor, dtype=tf.int64\n",
    "    )\n",
    "\n",
    "    b = tf.shape(dat[\"inputFeatures\"])[0]\n",
    "    t = tf.cast(tf.shape(dat[\"inputFeatures\"])[1], dtype=tf.int32)\n",
    "    warppedT = tf.cast(tf.cast(t, dtype=tf.float32) * globalTimeFactor, dtype=tf.int32)\n",
    "    newIdx = tf.linspace(\n",
    "        tf.zeros_like(dat[\"nTimeSteps\"], dtype=tf.int32),\n",
    "        tf.ones_like(dat[\"nTimeSteps\"], dtype=tf.int32) * (t - 1),\n",
    "        warppedT,\n",
    "        axis=1,\n",
    "    )\n",
    "    newIdx = tf.cast(newIdx, dtype=tf.int32)\n",
    "    batchIdx = tf.tile(tf.range(b)[:, None, None], [1, warppedT, 1])\n",
    "    newIdx = tf.concat([batchIdx, newIdx[..., None]], axis=-1)\n",
    "    warpDat[\"inputFeatures\"] = tf.gather_nd(dat[\"inputFeatures\"], newIdx)\n",
    "    # warpDat['classLabelsOneHot'] = tf.gather(\n",
    "    #    dat['classLabelsOneHot'], newIdx, axis=0)\n",
    "    warpDat[\"newClassSignal\"] = tf.gather_nd(dat[\"newClassSignal\"], newIdx)\n",
    "    warpDat[\"ceMask\"] = tf.gather_nd(dat[\"ceMask\"], newIdx)\n",
    "\n",
    "    return warpDat\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#     loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#     from_logits=True, reduction='none')\n",
    "#     mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "#     loss_ = loss_object(real, pred)\n",
    "\n",
    "#     mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     loss_ *= mask\n",
    "\n",
    "#     return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "# Only decoder\n",
    "def loss_function(real, pred):\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "def _wer(reference, hypothesis):\n",
    "    # Create a 2D matrix to store the distances\n",
    "    distance = [[0] * (len(hypothesis) + 1) for _ in range(len(reference) + 1)]\n",
    "\n",
    "    # Initialize the matrix with the distances\n",
    "    for i in range(len(reference) + 1):\n",
    "        for j in range(len(hypothesis) + 1):\n",
    "            if i == 0:\n",
    "                distance[i][j] = j\n",
    "            elif j == 0:\n",
    "                distance[i][j] = i\n",
    "            else:\n",
    "                cost = 0 if reference[i - 1] == hypothesis[j - 1] else 1\n",
    "                distance[i][j] = min(\n",
    "                    distance[i - 1][j] + 1,      # Deletion\n",
    "                    distance[i][j - 1] + 1,      # Insertion\n",
    "                    distance[i - 1][j - 1] + cost  # Substitution\n",
    "                )\n",
    "\n",
    "    # Return the WER\n",
    "    return distance[len(reference)][len(hypothesis)] / len(reference)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (size, size)\n",
    "\n",
    "def create_decoder_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # Add extra dimensions to add the padding to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
    "\n",
    "def calculate_cer(predicted, target):\n",
    "    m = len(predicted)\n",
    "    n = len(target)\n",
    "\n",
    "    # Create a matrix to store edit distances\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Initialize the matrix\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Calculate edit distances\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            cost = 0 if predicted[i - 1] == target[j - 1] else 1\n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j] + 1,  # Deletion\n",
    "                dp[i][j - 1] + 1,  # Insertion\n",
    "                dp[i - 1][j - 1] + cost,\n",
    "            )  # Substitution\n",
    "\n",
    "    # CER calculation\n",
    "    cer = dp[m][n] / n  # Divide by the total number of characters in the reference\n",
    "    return cer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubsampledTimeSteps(timeSteps):\n",
    "    timeSteps = tf.cast(timeSteps / 1, dtype=tf.int32)\n",
    "    timeSteps = tf.cast(\n",
    "        (timeSteps - 14)\n",
    "        / 4\n",
    "        + 1,\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "    return timeSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = '/home/s2/nlp002/pj_data'\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.04.28/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.04.28/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.05/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.05/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.17/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.17/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.19/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.19/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.24/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.24/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.26/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.05.26/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.02/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.02/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.07/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.07/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.14/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.14/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.16/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.16/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.21/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.21/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.28/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.06.28/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.05/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.05/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.14/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.14/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.21/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.21/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.27/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.07.27/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.02/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.02/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.11/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.11/competitionHoldOut\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.13/train\n",
      "Load data from /home/s2/nlp002/pj_data/derived/tfRecords/t12.2022.08.13/competitionHoldOut\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_43 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_47 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_59 (Dense)            (None, None, 256)         65792     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,792\n",
      "Trainable params: 65,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model weights loaded from /home/s2/nlp002/pj_data/derived/tr_to_ph/baselineRelease/7000_model_weights.h5\n",
      "--------------- Start Validation Step --------------\n",
      "-------------------- FIND PROPER END STEP ------------------------\n",
      "\n",
      "SAMPLES\n",
      "tf.Tensor(\n",
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8], shape=(64,), dtype=int64)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4194201/1606367136.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datasetProbabilityVal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msessIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datasetProbabilityVal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msessIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataDir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msessIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/derived/tfRecords'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testDir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestDirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdirIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4194201/390306621.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, returnData, load, weights_path)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfValDatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasetIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0minfOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0minfOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4194201/390306621.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, layerIdx)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputTransformedFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0;31m# Only Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputTransformedFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;31m# output = tf.transpose(output_array.stack())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;31m# predictions, _ = self.model([inputTransformedFeatures, output], training = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4194201/3780865680.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n\u001b[0m\u001b[1;32m    259\u001b[0m                                              look_ahead_mask, padding_mask)\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'decoder_layer{i+1}_block1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4194201/3780865680.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mattn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_block1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mattn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     attn2, attn_weights_block2 = self.mha2(\n\u001b[0m\u001b[1;32m    185\u001b[0m         enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n\u001b[1;32m    186\u001b[0m     \u001b[0mattn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4194201/3780865680.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, num_heads, seq_len_v, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     scaled_attention, attention_weights = scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    117\u001b[0m         q, k, v, mask)\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len_q, num_heads, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4194201/3780865680.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(q, k, v, mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \"\"\"\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mmatmul_qk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (..., seq_len_q, seq_len_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;31m# scale matmul_qk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mdk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3696\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjoint_b\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3697\u001b[0m         return gen_math_ops.batch_mat_mul_v3(\n\u001b[1;32m   3698\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3699\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3700\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3701\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n",
      "\u001b[0;32m~/anaconda3/envs/pj/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1573\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m       return batch_mat_mul_v2_eager_fallback(\n\u001b[1;32m   1580\u001b[0m           x, y, adj_x=adj_x, adj_y=adj_y, name=name, ctx=_ctx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#evaluate the RNN on the test partition and competitionHoldOut partition\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_file_name = \"/7000_model_weights.h5\"\n",
    "\n",
    "testDirs = ['test','competitionHoldOut']\n",
    "trueTranscriptions = [[],[]]\n",
    "decodedTranscriptions = [[],[]]\n",
    "for dirIdx in range(2):\n",
    "    ckptDir = baseDir + '/derived/tr_to_ph/baselineRelease'\n",
    "    dirIdx += 1\n",
    "    args = OmegaConf.load(os.path.join(ckptDir, 'args.yaml'))\n",
    "    args['loadDir'] = ckptDir\n",
    "    args['mode'] = 'infer'\n",
    "    args['loadCheckpointIdx'] = None\n",
    "\n",
    "    for x in range(len(args['dataset']['datasetProbabilityVal'])):\n",
    "        args['dataset']['datasetProbabilityVal'][x] = 0.0\n",
    "\n",
    "    for sessIdx in range(4,19):\n",
    "        args['dataset']['datasetProbabilityVal'][sessIdx] = 1.0\n",
    "        args['dataset']['dataDir'][sessIdx] = baseDir+'/derived/tfRecords'\n",
    "    args['testDir'] = testDirs[dirIdx]\n",
    "\n",
    "    # Initialize model\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    nsd = NeuralSequenceDecoder(args)\n",
    "    nsd._load_model(ckptDir + model_file_name)\n",
    "    # Inference\n",
    "    out = nsd.inference()\n",
    "    \n",
    "    print(out)\n",
    "    break\n",
    "\n",
    "    # trueTranscriptions[dirIdx] = out['targetSentences']\n",
    "    # decodedTranscriptions[dirIdx] = out[\"decodedSentences\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
